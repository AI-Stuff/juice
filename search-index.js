var N=null,E="",T="t",U="u",searchIndex={};
var R=["The vector that stores shared references to the weights in…","References to all the input blobs of the layer.","References to all the output blobs of the layer.","Dropout","arclock","sharedtensor","option","usize","A Layer that can compute the gradient with respect to its…","hashmap","Uses the underlying layer implementation to compute a…","backward_input","backward_parameters","input_blob_names","learnable_weights_gradients","learnable_weights_names","learnable_weights_lr","layertype","layerconfig","string","weightconfig","juice::layers::activation","juice::layers","Convolution","Convolution Layer","from_config","convolution","juice::layers::common","Linear Layer","LogSoftmax","LogSoftmax Layer","Pooling Layer","filter_shape","The stride size","The padding size","Softmax Layer","padding","NegativeLogLikelihood","juice::layers::loss","MeanSquaredError","juice::layers::utility","reshape","reshapeconfig","Sequential","Sequential Layer","sequential","sequentialconfig","add_input","Provides the generics and interfaces for the specific…","The [LayerConfig][1] that is used to initialize the…","TODO: DOC","accuracy","juice::solver","add_sample","add_samples","Add a batch of samples.","get_predictions","set_capacity","Return all collected samples.","vecdeque","Return the accuracy of the collected predictions.","solverconfig","Returns the network trained by the solver.","ibackend","with_config","Create a Solver of the specified kind with the supplied…","solverops","isolver","momentum","Momentum","juice::weight","juice::weight::FillerType","output_size","decay_mult","result","juice::layer","try_from","try_into","borrow_mut","to_owned","clone_into","type_id","juice::layers::activation::relu","juice::layers::activation::sigmoid","borrow","typeid","juice::layers::activation::tanh","juice::layers::common::convolution","juice::layers::common::rnn","juice::layers::common::linear","juice::layers::common::log_softmax","juice::layers::common::pooling","juice::layers::common::softmax","juice::layers::common::dropout","juice::layers::loss::negative_log_likelihood","juice::layers::loss::mean_squared_error","juice::layers::utility::flatten","juice::layers::utility::reshape","juice::layers::container::sequential","juice::solver::confusion_matrix","to_string","juice::solver::regression_evaluator","juice::solvers::sgd::momentum","exact_num_output_blobs","exact_num_input_blobs","compute_in_place","auto_weight_blobs","resize_shared_workspace","auto_output_blobs","loss_weight","sync_native","is_container","inputs_data","inputs_gradients","outputs_data","outputs_gradients","learnable_weights","compute_output","compute_input_gradient","compute_parameters_gradient","num_spatial_dims","Calculates the number of spatial dimensions for the…","calculate_output_shape","compute_update","convolutionconfig","rnnconfig","linearconfig","poolingconfig","dropoutconfig","negativeloglikelihood","negativeloglikelihoodconfig","logsoftmax","meansquarederror","default","formatter","LayerConfig","LayerType","ComputeOutput","ComputeInputGradient","ComputeParametersGradient","ConvolutionConfig","RnnConfig","LinearConfig","PoolingConfig","PoolingMode","DropoutConfig","FilterLayer","NegativeLogLikelihoodConfig","ReshapeConfig","SequentialConfig","SolverConfig","SolverKind","RegularizationMethod","ConfusionMatrix","RegressionLoss","RegressionEvaluator","WeightConfig","DimCheckMode","FillerType","MeanSquaredErrorAccuracy"];

searchIndex["juice"]={"doc":"Juice is a open, modular and clear-designed Machine…","i":[[0,"layer","juice",R[48],N,N],[3,"Layer",R[75],"The generic Layer",N,N],[12,"name",E,"Identifies the Network",0,N],[12,"config",E,"The configuration of the Layer",0,N],[12,"worker",E,"The [implementation][1] of the Layer. [1]:…",0,N],[12,"weights_data",E,R[0],0,N],[12,"weights_gradient",E,R[0],0,N],[12,"input_blobs_data",E,R[1],0,N],[12,"input_blobs_gradient",E,R[1],0,N],[12,R[13],E,"Names for all the input blobs of the layer.",0,N],[12,"output_blobs_data",E,R[2],0,N],[12,"output_blobs_gradient",E,R[2],0,N],[12,"blob_names",E,"All the blobs of the layer that can be addressed by name.",0,N],[3,R[135],E,"Layer Configuration Struct",N,N],[12,"name",E,"The name of the Layer",1,N],[12,"layer_type",E,"The type of the Layer",1,N],[12,"outputs",E,"The name for each output Blob",1,N],[12,"inputs",E,"The name for each input Blob",1,N],[12,"params",E,"Specifies training configuration for each weight blob.",1,N],[12,"propagate_down",E,"Specifies on which inputs the backpropagation should be…",1,N],[4,R[136],E,"The Layer Types",N,N],[13,R[23],E,R[24],2,N],[13,"Rnn",E,"RNN Layer",2,N],[13,"Linear",E,R[28],2,N],[13,R[29],E,R[30],2,N],[13,"Pooling",E,R[31],2,N],[13,R[43],E,R[44],2,N],[13,"Softmax",E,R[35],2,N],[13,R[3],E,R[3],2,N],[13,"ReLU",E,"ReLU Layer",2,N],[13,"TanH",E,"TanH Layer",2,N],[13,"Sigmoid",E,"Sigmoid Layer",2,N],[13,R[37],E,"NegativeLogLikelihood Layer",2,N],[13,R[39],E,"MeanSquaredError Layer",2,N],[13,"Reshape",E,"Reshape Layer",2,N],[8,"ILayer",E,"A Layer in a Neural Network that can handle forward and…",N,N],[11,"init",E,"Initialize the layer for computation.",3,[[["rc"],["self"]]]],[11,R[41],E,"Adjust to shapes of the output blobs to fit the shapes of…",3,[[["rc"],["vec"],["self"]]]],[11,R[107],E,"Adjust size of shared workspace.",3,[[["rc"],["self"],[R[4],[R[5]]],[R[6],[R[4]]]],[[R[4],[R[5]]],[R[6],[R[4]]]]]],[11,"forward",E,"Compute the [feedforward][1] layer output using the…",3,[[["b"],["self"]]]],[11,R[11],E,"Compute the [backpropagation][1] input gradient using the…",3,[[["b"],["self"]]]],[11,R[12],E,"Compute the [backpropagation][1] parameters gradient using…",3,[[["b"],["self"]]]],[11,R[108],E,"Return whether \"anonymous\" output blobs are created…",3,[[["self"]],["bool"]]],[11,"min_output_blobs",E,"Returns the minimum number of output blobs required by the…",3,[[["self"]],[R[7]]]],[11,R[103],E,"Returns the exact number of output blobs required by the…",3,[[["self"]],[[R[6],[R[7]]],[R[7]]]]],[11,R[106],E,"Return whether weight blobs are created automatically for…",3,[[["self"]],["bool"]]],[11,R[104],E,"Returns the exact number of input blobs required by the…",3,[[["self"]],[[R[6],[R[7]]],[R[7]]]]],[11,"allow_force_backward",E,"Return whether to allow force_backward for a given input…",3,[[["self"],[R[7]]],["bool"]]],[11,R[110],E,"Return wether a simple native backend should be used to…",3,[[["self"]],["bool"]]],[11,R[105],E,"Return wether the computations of a layer should be done…",3,[[["self"]],["bool"]]],[11,R[111],E,"Return wether the layer is a container.",3,[[["self"]],["bool"]]],[11,R[109],E,"Return the associated loss weight for a given output blob…",3,[[["self"],[R[7]]],[["f32"],[R[6],["f32"]]]]],[11,R[112],E,"Return the input tensors of the layer.",3,[[["self"]],[[R[6],["vec"]],["vec",[R[4]]]]]],[11,R[113],E,"Return the gradients of the input tensors of the layer.",3,[[["self"]],[[R[6],["vec"]],["vec",[R[4]]]]]],[11,R[114],E,"Return the output tensors of the layer.",3,[[["self"]],[[R[6],["vec"]],["vec",[R[4]]]]]],[11,R[115],E,"Return the gradients of the output tensors of the layer.",3,[[["self"]],[[R[6],["vec"]],["vec",[R[4]]]]]],[11,R[116],E,"Return the learnable weights inside the layer.",3,[[["self"]],[[R[6],["vec"]],["vec",[R[4]]]]]],[11,R[14],E,"Return the gradients for the learnable weights inside the…",3,[[["self"]],[[R[6],["vec"]],["vec",[R[4]]]]]],[11,R[15],E,"Return the names of the learnable weights inside the layer.",3,[[["self"]],[[R[6],["vec"]],["vec",[R[19]]]]]],[11,R[16],E,"Return the learning rates for the learnable weights inside…",3,[[["self"]],[["vec",[R[6]]],[R[6],["vec"]]]]],[8,R[137],E,"A Layer that can compute the output for a given input.",N,N],[10,R[117],E,"Compute output for given input and write them into…",4,[[["b"],["self"]]]],[8,R[138],E,R[8],N,N],[10,R[118],E,"Compute gradients with respect to the inputs and write…",5,[[["b"],["self"]]]],[8,R[139],E,R[8],N,N],[11,R[119],E,"Compute gradients with respect to the parameters and write…",6,[[["b"],["self"]]]],[11,"connect",E,"Connect the layer to another layers and set up tensors for…",0,[[[R[9]],["self"],[R[9]]]]],[11,"init_backprop",E,"Initializes layer for [backpropagation][1] [1]:…",0,[[["self"],["hashset"]]]],[11,"init_force_backward",E,"Set [backpropagation][1] flags to force this layer to…",0,[[["self"]]]],[11,"forward",E,R[10],0,[[["self"]],[["vec",[R[4]]],[R[4],[R[5]]]]]],[11,"backward",E,R[10],0,[[["self"]],[["vec",[R[4]]],[R[4],[R[5]]]]]],[11,R[11],E,"Calculate the gradient w.r.t. input.",0,[[["self"]],[["vec",[R[4]]],[R[4],[R[5]]]]]],[11,R[12],E,"Calculate the gradient w.r.t. parameters.",0,[[["self"]]]],[11,"synchronize",E,"Synchronize the layers backend.",0,[[["self"]]]],[11,"update_weights",E,"Updates the [weights][1] with the weight update computed…",0,[[["self"],["solverb"]]]],[11,"clear_weights_gradients",E,"Clears the [weights][1] gradients and zero-inits them.…",0,[[["self"]]]],[11,"save",E,"Serialize the Layer and it's weights to a Cap'n Proto file…",0,[[["self"],["path"],["asref",["path"]]],[R[74]]]],[11,"load",E,"Read a Cap'n Proto file at the specified path and…",0,[[["f32"],["rc"],["path"],[R[63]],["layerops",["f32"]],["asref",["path"]]],[["layer"],[R[74],["layer"]]]]],[11,"set_weight_propagate_down",E,"Sets whether the layer should compute gradients w.r.t. a…",0,[[["self"],[R[7]],["bool"]]]],[11,"is_using_in_place",E,"Returns `true` when the layer is using in-place computation.",0,[[["self"]],["bool"]]],[11,R[13],E,"Returns the names of all the input blobs.",0,[[["self"]]]],[11,"loss",E,"Returns the [loss weight][1] associated with the weight…",0,[[["self"],[R[7]]],[["f32"],[R[6],["f32"]]]]],[11,"learnable_weights_data",E,"Returns all the learnable weights in the layer.",0,[[["self"]],[["vec",[R[4]]],[R[4],[R[5]]]]]],[11,R[14],E,"Returns the gradients for all the learnable weights in the…",0,[[["self"]],[["vec",[R[4]]],[R[4],[R[5]]]]]],[11,R[15],E,"Returns the names of all the learnable weights in the layer.",0,[[["self"]],[[R[19]],["vec",[R[19]]]]]],[11,R[16],E,"Returns the learning rate for all the learnable weights in…",0,[[["self"]],[["vec",[R[6]]],[R[6],["f32"]]]]],[11,R[25],E,"Creates a new Layer from a [LayerConfig][1]. [1]:…",0,[[["rc"],[R[18]]],["layer"]]],[11,"supports_in_place",E,"Returns wether the LayerType supports in-place operations.",2,[[["self"]],["bool"]]],[11,"new",E,"Creates a new LayerConfig",1,[[["str"],["into",[R[17]]],[R[17]]],[R[18]]]],[11,"output",E,"Returns the Name of the requested output Blob",1,[[["self"],[R[7]]],[[R[6],[R[19]]],[R[19]]]]],[11,"outputs_len",E,"Returns the number of output Blobs",1,[[["self"]],[R[7]]]],[11,"add_output",E,"Add a output by name",1,[[["str"],["self"]]]],[11,"input",E,"Returns the Name of the requested input Blob",1,[[["self"],[R[7]]],[[R[6],[R[19]]],[R[19]]]]],[11,"inputs_len",E,"Returns the number of input Blobs",1,[[["self"]],[R[7]]]],[11,R[47],E,"Add a input by name",1,[[["str"],["self"]]]],[11,"param",E,"Returns the requested WeightConfig",1,[[["self"],[R[7]]],[[R[20]],[R[6],[R[20]]]]]],[11,"params_len",E,"Returns the number of params",1,[[["self"]],[R[7]]]],[11,"validate",E,"Check if the configured parameters make sense.",1,[[["self"]],[[R[74],["str"]],["str"]]]],[0,"layers","juice","Provides the fundamental units of computation in a Neural…",N,N],[0,"activation",R[22],"Provides nonlinear activation methods.",N,N],[0,"relu",R[21],"Applies the nonlinear Rectified Linear Unit.",N,N],[3,"ReLU",R[82],"ReLU Activation Layer",N,N],[0,"sigmoid",R[21],"Applies the nonlinear Log-Sigmoid function.",N,N],[3,"Sigmoid",R[83],"Sigmoid Activation Layer",N,N],[0,"tanh",R[21],"Applies the nonlinear TanH function.",N,N],[3,"TanH",R[86],"TanH Activation Layer",N,N],[0,"common",R[22],"Provides common neural network layers.",N,N],[0,R[26],R[27],"Convolves the input tensor.",N,N],[3,R[23],R[87],R[24],N,N],[3,R[140],E,"Specifies configuration parameters for a Convolution Layer.",N,N],[12,"num_output",E,"The number of output feature maps",7,N],[12,R[32],E,"The size of the kernel",7,N],[12,"stride",E,R[33],7,N],[12,R[36],E,R[34],7,N],[11,R[25],E,"Create a Convolution layer from a ConvolutionConfig.",8,[[[R[124]]],[R[26]]]],[0,"rnn",R[27],"Create a Recursive Layer",N,N],[3,"Rnn",R[88],E,N,N],[3,R[141],E,"Specifies configuration parameters for a RNN Layer. TODO:…",N,N],[12,"hidden_size",E,"Size of the Hidden Layer",9,N],[12,"num_layers",E,"Number of Hidden Layers",9,N],[12,"dropout_probability",E,"Dropout Probability",9,N],[12,"dropout_seed",E,"Dropout Seed",9,N],[12,"rnn_type",E,"Type of RNN",9,N],[12,"input_mode",E,"Input Mode",9,N],[12,"direction_mode",E,"RNN Direction",9,N],[11,R[25],E,"Create a RNN from a RNNConfig",10,[[[R[125]]],["rnn"]]],[0,"linear",R[27],"Applies a linear transformation to the input data `y = a *…",N,N],[3,"Linear",R[89],R[28],N,N],[3,R[142],E,"Specifies configuration parameters for a Linear Layer.",N,N],[12,R[72],E,"The number of output values",11,N],[11,R[25],E,"Create a Linear layer from a LinearConfig.",12,[[[R[126]]],["linear"]]],[0,"log_softmax",R[27],"Computes the logarithmic softmax of its input.",N,N],[3,R[29],R[90],R[30],N,N],[0,"pooling",R[27],"Applies pooling to the input.",N,N],[3,"Pooling",R[91],R[31],N,N],[3,R[143],E,"Specifies configuration parameters for a Pooling Layer.",N,N],[12,"mode",E,"The PoolingMode to use",13,N],[12,R[32],E,"The shape of the filter",13,N],[12,"stride",E,R[33],13,N],[12,R[36],E,R[34],13,N],[4,R[144],E,"The different modes of pooling that can be calculated.",N,N],[13,"Max",E,"The maximum value inside the pooling window will be used…",14,N],[13,"Average",E,"The average of all values inside the pooling window will…",14,N],[11,R[25],E,"Create a Pooling layer from a PoolingConfig.",15,[[[R[127]]],["pooling"]]],[0,"softmax",R[27],"Computes the softmax of its input.",N,N],[3,"Softmax",R[92],R[35],N,N],[0,"dropout",R[27],"Applies a Dropout layer to the input data `x`",N,N],[3,R[3],R[93],"Dropout Layer",N,N],[3,R[145],E,"Specifies configuration parameters for a Dropout Layer.",N,N],[12,"probability",E,"The probability to clamp a value to zero",16,N],[12,"seed",E,"The initial seed for the (pseudo-)random generator",16,N],[11,R[25],E,"Create a Dropout layer from a DropoutConfig.",17,[[[R[128]]],["dropout"]]],[8,R[146],R[27],"Provides common utilities for Layers that utilize a filter…",N,N],[11,"calculate_spatial_output_dims",E,"Computes the shape of the spatial dimensions.",18,[[],[[R[7]],["vec",[R[7]]]]]],[10,R[122],E,"Calculate output shape based on the shape of filter,…",18,[[["self"]],[[R[7]],["vec",[R[7]]]]]],[10,R[120],E,R[121],18,[[["self"]],[R[7]]]],[11,"spatial_filter_dims",E,"Retrievs the spatial dimensions for the filter based on…",18,[[["self"],[R[7]]],[[R[7]],["vec",[R[7]]]]]],[11,"stride_dims",E,"Retrievs the stride for the convolution based on…",18,[[["self"],[R[7]]],[[R[7]],["vec",[R[7]]]]]],[11,"padding_dims",E,"Retrievs the padding for the convolution based on…",18,[[["self"],[R[7]]],[[R[7]],["vec",[R[7]]]]]],[10,R[32],E,"The filter_shape that will be used by `spatial_filter_dims`.",18,[[["self"]]]],[10,"stride",E,"The stride that will be used by `stride_dims`.",18,[[["self"]]]],[10,R[36],E,"The padding that will be used by `padding_dims`.",18,[[["self"]]]],[0,"loss",R[22],"Provides methods to calculate the loss (cost) of some…",N,N],[0,"negative_log_likelihood",R[38],R[50],N,N],[3,R[37],R[94],"NegativeLogLikelihood Loss Layer",N,N],[3,R[147],E,"Specifies configuration parameters for a…",N,N],[12,"num_classes",E,"How many different classes can be classified.",19,N],[11,R[25],E,"Create a NegativeLogLikelihood layer from a…",20,[[[R[130]]],[R[129]]]],[0,"mean_squared_error",R[38],"Provides Loss & Gradient for Mean Squared Error",N,N],[3,R[39],R[95],"Mean Squared Error Layer",N,N],[0,"utility",R[22],"Provides various helpful layers, which might be not…",N,N],[0,"flatten",R[40],"Flattens the bottom Blob into a simpler top Blob.",N,N],[3,"Flatten",R[96],"Flattening Utility Layer",N,N],[0,R[41],R[40],"Utility layer to give a tensor another shape.",N,N],[3,"Reshape",R[97],"Reshape Utility Layer",N,N],[3,R[148],E,"Specifies configuration parameters for a Reshape Layer.",N,N],[12,"shape",E,"The target shape that the input should assume.",21,N],[11,R[25],E,"Create a Reshape layer from a ReshapeConfig.",22,[[[R[42]]],[R[41]]]],[11,"of_shape",E,"Create a ReshapeConfig that describes a Reshape layer with…",21,[[],[R[42]]]],[0,"container",R[22],"Provides container layers.",N,N],[0,R[45],"juice::layers::container","A container layer that runs operations sequentially on the…",N,N],[3,R[43],R[98],R[44],N,N],[3,R[149],E,"Specifies configuration parameters for a Sequential Layer.",N,N],[12,"layers",E,"Defines the layers of the container via…",23,N],[12,"inputs",E,"Defines the names and shapes of the input tensors.",23,N],[12,"force_backward",E,"Defines if the container will force every layer to do…",23,N],[11,"empty",E,"Create a empty Sequential container layer.",24,[[],[R[45]]]],[11,R[25],E,"Create a Sequential layer from a SequentialConfig.",24,[[["rc"],[R[46]]],[R[45]]]],[11,"init_layers",E,"Initializes a sequential container.",24,[[["rc"],["self"],[R[46]]]]],[11,"find_in_place_output",E,"Tries to find the output of a previous layer that is…",23,[[["self"],[R[7]]],[[R[19]],[R[6],[R[19]]]]]],[11,"add_layer",E,"Add layer at the end of the sequential container.",23,[[[R[18]],["self"]]]],[11,R[47],E,"Add a input to the network.",23,[[["str"],["self"]]]],[0,"solver","juice",R[48],N,N],[3,"Solver",R[52],"Solver that optimizes a [Layer][1] with a given objective.…",N,N],[12,"worker",E,"The implementation of the Solver",25,N],[3,R[150],E,"Configuration for a Solver",N,N],[12,"name",E,"Name of the solver.",26,N],[12,"network",E,R[49],26,N],[12,"objective",E,R[49],26,N],[12,"solver",E,"The [Solver implementation][1] to be used. [1]:…",26,N],[12,"minibatch_size",E,"Accumulate gradients over `minibatch_size` instances.",26,N],[12,"lr_policy",E,"The learning rate policy to be used.",26,N],[12,"base_lr",E,"The base learning rate.",26,N],[12,"gamma",E,"gamma as used in the calculation of most learning rate…",26,N],[12,"stepsize",E,"The stepsize used in Step and Sigmoid learning policies.",26,N],[12,"clip_gradients",E,"The threshold for clipping gradients.",26,N],[12,"weight_decay",E,"The global [weight decay][1] multiplier for…",26,N],[12,"regularization_method",E,"The method of [regularization][1] to use. [1]:…",26,N],[12,R[68],E,"The [momentum][1] multiplier for [SGD solvers][2]. [1]:…",26,N],[4,R[151],E,"All available types of solvers.",N,N],[13,"SGD",E,"Stochastic Gradient Descent. See [SGDKind][1] for all…",27,N],[4,"SGDKind",E,"All available types of Stochastic Gradient Descent solvers.",N,N],[13,R[69],E,"Stochastic Gradient Descent with Momentum. See…",28,N],[4,"LRPolicy",E,"Learning Rate Policy for a [Solver][1] [1]:…",N,N],[13,"Fixed",E,"always return base_lr",29,N],[13,"Step",E,"learning rate decays every `step` iterations. return…",29,N],[13,"Exp",E,"return base_lr * gamma ^ iter",29,N],[4,R[152],E,"[Regularization][1] method for a [Solver][2]. [1]:…",N,N],[13,"L2",E,"L2 regularization",30,N],[0,"confusion_matrix",E,R[50],N,N],[3,R[153],R[99],"A [ConfusionMatrix][wiki].",N,N],[3,"Sample",E,"A single prediction Sample.",N,N],[3,"Accuracy",E,"The accuracy of the predictions in a ConfusionMatrix.",N,N],[11,"new",E,"Create a ConfusionMatrix that analyzes the prediction of…",31,[[[R[7]]],["confusionmatrix"]]],[11,R[53],E,"Add a sample by providing the expected `target` class and…",31,[[["self"],[R[7]]]]],[11,R[54],E,R[55],31,[[["self"]]]],[11,R[56],E,"Get the predicted classes from the output of a network.",31,[[["self"],[R[5]]],[[R[7]],["vec",[R[7]]]]]],[11,R[57],E,"Set the `capacity` of the ConfusionMatrix",31,[[[R[6],[R[7]]],["self"],[R[7]]]]],[11,"samples",E,R[58],31,[[["self"]],[R[59]]]],[11,R[51],E,R[60],31,[[["self"]],[R[51]]]],[11,"correct",E,"Returns if the prediction is equal to the expected target.",32,[[["self"]],["bool"]]],[0,"regression_evaluator",R[52],"Set of Evaluators for Regression Problems",N,N],[3,R[155],R[101],"Sampled Evaluator for Regression Problems",N,N],[3,"Sample",E,"A single prediction sample.",N,N],[3,R[159],E,"Provides loss calculated by Mean Squared Error for sampled…",N,N],[8,R[154],E,"Trait to show loss & metric for a Regression Evaluator",N,N],[10,"loss",E,"Loss function to produce metric",33,[[["self"]],["f32"]]],[11,"new",E,"Create an evaluator for Regression Problems",34,[[[R[19]],[R[6],[R[19]]]],["regressionevaluator"]]],[11,R[53],E,"Add a sample by providing the expected `target` value and…",34,[[["f32"],["self"]]]],[11,R[54],E,R[55],34,[[["self"]]]],[11,R[56],E,"Get the predicted value from the output of a network.",34,[[["self"],[R[5]]],[["f32"],["vec",["f32"]]]]],[11,R[57],E,"Set the `capacity` of the Regression Evaluator",34,[[[R[6],[R[7]]],["self"],[R[7]]]]],[11,"samples",E,R[58],34,[[["self"]],[R[59]]]],[11,R[51],E,R[60],34,[[["self"]]]],[8,"ISolver",R[52],"Implementation of a specific Solver.",N,N],[11,"init",E,"Initialize the solver, setting up any network related data.",35,[[["self"],["layer"]]]],[10,R[123],E,"Update the weights of the net with part of the gradient.",35,[[["layer"],[R[7]],["self"],[R[61]]]]],[10,"backend",E,"Returns the backend used by the solver.",35,[[["self"]],["solverb"]]],[11,R[25],E,"Create Solver from [SolverConfig][1] [1]:…",25,[[["rc"],[R[61]],["rc"]],["solver"]]],[11,"train_minibatch",E,"Train the network with one minibatch",25,[[[R[5],["f32"]],["self"],[R[4],[R[5]]]],[[R[5],["f32"]],[R[4],[R[5]]]]]],[11,"network",E,R[62],25,[[["self"]],["layer"]]],[11,"mut_network",E,R[62],25,[[["self"]],["layer"]]],[11,"get_learning_rate",E,"Return the learning rate for a supplied iteration.",26,[[["self"],[R[7]]],["f32"]]],[11,R[64],E,R[65],27,[[["rc"],["f32"],[R[61]],[R[63]],["self"],[R[66],["f32"]]],[["box",[R[67]]],[R[67]]]]],[11,R[64],E,R[65],28,[[["rc"],["f32"],[R[61]],[R[63]],["self"],[R[66],["f32"]]],[["box",[R[67]]],[R[67]]]]],[0,"solvers","juice","Provides the trainers for the Layers.",N,N],[0,"sgd","juice::solvers","Provides ISolver implementations based on [Stochastic…",N,N],[0,R[68],"juice::solvers::sgd","A [Stochastic Gradient Descent with Momentum][1] [1]:…",N,N],[3,R[69],R[102],"Stochastic Gradient Descent with Momentum.",N,N],[11,"new",E,"Create a new SGD Momentum solver.",36,[[["rc"]],[R[68]]]],[0,"weight","juice","Provides configuration of weights and their initialization.",N,N],[3,R[156],R[70],"Specifies training configuration for a weight blob.",N,N],[12,"name",E,"The name of the weight blob -- useful for sharing weights…",37,N],[12,"share_mode",E,"Whether to require shared weights to have the same shape,…",37,N],[12,"lr_mult",E,"The multiplier on the global learning rate for this…",37,N],[12,R[73],E,"The multiplier on the global weight decay for this…",37,N],[12,"filler",E,"The filler that initializes the weights in the weight blob.",37,N],[4,R[157],E,"Enum for specifing the shared weights behaviour",N,N],[13,"Strict",E,"Strict requires that shapes match.",38,N],[13,"Permissive",E,"Permissive requires only the count of weights to match.",38,N],[4,R[158],E,"Enum for specifing the type of Filler.",N,N],[13,"Constant",E,"Fills the weight blob with a constant `value` (all values…",39,N],[12,"value",R[71],"The value that will be used to fill the blob.",39,N],[13,"Glorot",R[70],"Fills the weight blobs based on the paper:",39,N],[12,"input_size",R[71],"Number of input nodes for each output.",39,N],[12,R[72],E,"Number of output nodes for each input.",39,N],[11,"check_dimensions",R[70],"Checks dimensions of two blobs according to the…",37,[[[R[5]],[R[19]],["self"]],[[R[74],[R[19]]],[R[19]]]]],[11,"lr_mult",E,"The multiplier on the global learning rate for this weight…",37,[[["self"]],["f32"]]],[11,R[73],E,"The multiplier on the global weight decay for this weight…",37,[[["self"]],["f32"]]],[11,"fill",E,"Uses a filler as specified by this FillerType to fill the…",39,[[["self"],[R[5]]]]],[11,"fill_constant",E,"Directly use the Constant Filler.",39,[[["f32"],[R[5]]]]],[11,"fill_glorot",E,"Directly use the Glorot Filler.",39,[[[R[5]],[R[7]]]]],[0,"util","juice","Provides common utility functions",N,N],[5,"native_backend","juice::util","Create a simple native backend.",N,[[],[["native"],["backend",["native"]]]]],[5,"write_to_memory",E,"Write into a native Coaster Memory.",N,[[["flatbox"]]]],[5,"write_to_memory_offset",E,"Write into a native Coaster Memory with a offset.",N,[[["flatbox"],[R[7]]]]],[5,"write_batch_sample",E,"Write the `i`th sample of a batch into a SharedTensor.",N,[[[R[7]],[R[5]]]]],[5,"native_scalar",E,"Create a Coaster SharedTensor for a scalar value.",N,[[["numcast"],["copy"]],[["numcast"],[R[5]],["copy"]]]],[5,"cast_vec_usize_to_i32",E,"Casts a Vec to as Vec",N,[[[R[7]],["vec",[R[7]]]],[["i32"],["vec",["i32"]]]]],[6,"ArcLock",E,"Shared Lock used for our tensors",N,N],[8,"Axpby",E,"Extends IBlas with Axpby",N,N],[11,"axpby",E,"Performs the operation y := ax + by .",40,[[[R[5]],["self"],[R[5]]],[[R[74],["error"]],["error"]]]],[8,"SolverOps",E,"Encapsulates all traits required by Solvers.",N,N],[8,"LayerOps",E,"Encapsulates all traits used in Layers.",N,N],[14,"impl_ilayer_activation","juice","macro helper to implement activation trait TODO see common",N,N],[14,"impl_ilayer_common",E,"macro to implement ilayer common TODO use Some(1) as a…",N,N],[14,"impl_ilayer_loss",E,"macro helper for default loss",N,N],[14,"impl_isolver_sgd",E,"Implement [ISolver][1] for [SGD solvers][2]. [1]:…",N,N],[11,"into",R[75],E,0,[[],[U]]],[11,"from",E,E,0,[[[T]],[T]]],[11,R[76],E,E,0,[[[U]],[R[74]]]],[11,R[77],E,E,0,[[],[R[74]]]],[11,R[84],E,E,0,[[["self"]],[T]]],[11,R[78],E,E,0,[[["self"]],[T]]],[11,R[81],E,E,0,[[["self"]],[R[85]]]],[11,"vzip",E,E,0,[[],["v"]]],[11,"into",E,E,1,[[],[U]]],[11,"from",E,E,1,[[[T]],[T]]],[11,R[79],E,E,1,[[["self"]],[T]]],[11,R[80],E,E,1,[[["self"],[T]]]],[11,R[76],E,E,1,[[[U]],[R[74]]]],[11,R[77],E,E,1,[[],[R[74]]]],[11,R[84],E,E,1,[[["self"]],[T]]],[11,R[78],E,E,1,[[["self"]],[T]]],[11,R[81],E,E,1,[[["self"]],[R[85]]]],[11,"vzip",E,E,1,[[],["v"]]],[11,"into",E,E,2,[[],[U]]],[11,"from",E,E,2,[[[T]],[T]]],[11,R[79],E,E,2,[[["self"]],[T]]],[11,R[80],E,E,2,[[["self"],[T]]]],[11,R[76],E,E,2,[[[U]],[R[74]]]],[11,R[77],E,E,2,[[],[R[74]]]],[11,R[84],E,E,2,[[["self"]],[T]]],[11,R[78],E,E,2,[[["self"]],[T]]],[11,R[81],E,E,2,[[["self"]],[R[85]]]],[11,"vzip",E,E,2,[[],["v"]]],[11,"into",R[82],E,41,[[],[U]]],[11,"from",E,E,41,[[[T]],[T]]],[11,R[79],E,E,41,[[["self"]],[T]]],[11,R[80],E,E,41,[[["self"],[T]]]],[11,R[76],E,E,41,[[[U]],[R[74]]]],[11,R[77],E,E,41,[[],[R[74]]]],[11,R[84],E,E,41,[[["self"]],[T]]],[11,R[78],E,E,41,[[["self"]],[T]]],[11,R[81],E,E,41,[[["self"]],[R[85]]]],[11,"vzip",E,E,41,[[],["v"]]],[11,"into",R[83],E,42,[[],[U]]],[11,"from",E,E,42,[[[T]],[T]]],[11,R[79],E,E,42,[[["self"]],[T]]],[11,R[80],E,E,42,[[["self"],[T]]]],[11,R[76],E,E,42,[[[U]],[R[74]]]],[11,R[77],E,E,42,[[],[R[74]]]],[11,R[84],E,E,42,[[["self"]],[T]]],[11,R[78],E,E,42,[[["self"]],[T]]],[11,R[81],E,E,42,[[["self"]],[R[85]]]],[11,"vzip",E,E,42,[[],["v"]]],[11,"into",R[86],E,43,[[],[U]]],[11,"from",E,E,43,[[[T]],[T]]],[11,R[79],E,E,43,[[["self"]],[T]]],[11,R[80],E,E,43,[[["self"],[T]]]],[11,R[76],E,E,43,[[[U]],[R[74]]]],[11,R[77],E,E,43,[[],[R[74]]]],[11,R[84],E,E,43,[[["self"]],[T]]],[11,R[78],E,E,43,[[["self"]],[T]]],[11,R[81],E,E,43,[[["self"]],[R[85]]]],[11,"vzip",E,E,43,[[],["v"]]],[11,"into",R[87],E,8,[[],[U]]],[11,"from",E,E,8,[[[T]],[T]]],[11,R[79],E,E,8,[[["self"]],[T]]],[11,R[80],E,E,8,[[["self"],[T]]]],[11,R[76],E,E,8,[[[U]],[R[74]]]],[11,R[77],E,E,8,[[],[R[74]]]],[11,R[84],E,E,8,[[["self"]],[T]]],[11,R[78],E,E,8,[[["self"]],[T]]],[11,R[81],E,E,8,[[["self"]],[R[85]]]],[11,"vzip",E,E,8,[[],["v"]]],[11,"into",E,E,7,[[],[U]]],[11,"from",E,E,7,[[[T]],[T]]],[11,R[79],E,E,7,[[["self"]],[T]]],[11,R[80],E,E,7,[[["self"],[T]]]],[11,R[76],E,E,7,[[[U]],[R[74]]]],[11,R[77],E,E,7,[[],[R[74]]]],[11,R[84],E,E,7,[[["self"]],[T]]],[11,R[78],E,E,7,[[["self"]],[T]]],[11,R[81],E,E,7,[[["self"]],[R[85]]]],[11,"vzip",E,E,7,[[],["v"]]],[11,"into",R[88],E,10,[[],[U]]],[11,"from",E,E,10,[[[T]],[T]]],[11,R[79],E,E,10,[[["self"]],[T]]],[11,R[80],E,E,10,[[["self"],[T]]]],[11,R[76],E,E,10,[[[U]],[R[74]]]],[11,R[77],E,E,10,[[],[R[74]]]],[11,R[84],E,E,10,[[["self"]],[T]]],[11,R[78],E,E,10,[[["self"]],[T]]],[11,R[81],E,E,10,[[["self"]],[R[85]]]],[11,"vzip",E,E,10,[[],["v"]]],[11,"into",E,E,9,[[],[U]]],[11,"from",E,E,9,[[[T]],[T]]],[11,R[79],E,E,9,[[["self"]],[T]]],[11,R[80],E,E,9,[[["self"],[T]]]],[11,R[76],E,E,9,[[[U]],[R[74]]]],[11,R[77],E,E,9,[[],[R[74]]]],[11,R[84],E,E,9,[[["self"]],[T]]],[11,R[78],E,E,9,[[["self"]],[T]]],[11,R[81],E,E,9,[[["self"]],[R[85]]]],[11,"vzip",E,E,9,[[],["v"]]],[11,"into",R[89],E,12,[[],[U]]],[11,"from",E,E,12,[[[T]],[T]]],[11,R[76],E,E,12,[[[U]],[R[74]]]],[11,R[77],E,E,12,[[],[R[74]]]],[11,R[84],E,E,12,[[["self"]],[T]]],[11,R[78],E,E,12,[[["self"]],[T]]],[11,R[81],E,E,12,[[["self"]],[R[85]]]],[11,"vzip",E,E,12,[[],["v"]]],[11,"into",E,E,11,[[],[U]]],[11,"from",E,E,11,[[[T]],[T]]],[11,R[79],E,E,11,[[["self"]],[T]]],[11,R[80],E,E,11,[[["self"],[T]]]],[11,R[76],E,E,11,[[[U]],[R[74]]]],[11,R[77],E,E,11,[[],[R[74]]]],[11,R[84],E,E,11,[[["self"]],[T]]],[11,R[78],E,E,11,[[["self"]],[T]]],[11,R[81],E,E,11,[[["self"]],[R[85]]]],[11,"vzip",E,E,11,[[],["v"]]],[11,"into",R[90],E,44,[[],[U]]],[11,"from",E,E,44,[[[T]],[T]]],[11,R[79],E,E,44,[[["self"]],[T]]],[11,R[80],E,E,44,[[["self"],[T]]]],[11,R[76],E,E,44,[[[U]],[R[74]]]],[11,R[77],E,E,44,[[],[R[74]]]],[11,R[84],E,E,44,[[["self"]],[T]]],[11,R[78],E,E,44,[[["self"]],[T]]],[11,R[81],E,E,44,[[["self"]],[R[85]]]],[11,"vzip",E,E,44,[[],["v"]]],[11,"into",R[91],E,15,[[],[U]]],[11,"from",E,E,15,[[[T]],[T]]],[11,R[79],E,E,15,[[["self"]],[T]]],[11,R[80],E,E,15,[[["self"],[T]]]],[11,R[76],E,E,15,[[[U]],[R[74]]]],[11,R[77],E,E,15,[[],[R[74]]]],[11,R[84],E,E,15,[[["self"]],[T]]],[11,R[78],E,E,15,[[["self"]],[T]]],[11,R[81],E,E,15,[[["self"]],[R[85]]]],[11,"vzip",E,E,15,[[],["v"]]],[11,"into",E,E,13,[[],[U]]],[11,"from",E,E,13,[[[T]],[T]]],[11,R[79],E,E,13,[[["self"]],[T]]],[11,R[80],E,E,13,[[["self"],[T]]]],[11,R[76],E,E,13,[[[U]],[R[74]]]],[11,R[77],E,E,13,[[],[R[74]]]],[11,R[84],E,E,13,[[["self"]],[T]]],[11,R[78],E,E,13,[[["self"]],[T]]],[11,R[81],E,E,13,[[["self"]],[R[85]]]],[11,"vzip",E,E,13,[[],["v"]]],[11,"into",E,E,14,[[],[U]]],[11,"from",E,E,14,[[[T]],[T]]],[11,R[79],E,E,14,[[["self"]],[T]]],[11,R[80],E,E,14,[[["self"],[T]]]],[11,R[76],E,E,14,[[[U]],[R[74]]]],[11,R[77],E,E,14,[[],[R[74]]]],[11,R[84],E,E,14,[[["self"]],[T]]],[11,R[78],E,E,14,[[["self"]],[T]]],[11,R[81],E,E,14,[[["self"]],[R[85]]]],[11,"vzip",E,E,14,[[],["v"]]],[11,"into",R[92],E,45,[[],[U]]],[11,"from",E,E,45,[[[T]],[T]]],[11,R[79],E,E,45,[[["self"]],[T]]],[11,R[80],E,E,45,[[["self"],[T]]]],[11,R[76],E,E,45,[[[U]],[R[74]]]],[11,R[77],E,E,45,[[],[R[74]]]],[11,R[84],E,E,45,[[["self"]],[T]]],[11,R[78],E,E,45,[[["self"]],[T]]],[11,R[81],E,E,45,[[["self"]],[R[85]]]],[11,"vzip",E,E,45,[[],["v"]]],[11,"into",R[93],E,17,[[],[U]]],[11,"from",E,E,17,[[[T]],[T]]],[11,R[79],E,E,17,[[["self"]],[T]]],[11,R[80],E,E,17,[[["self"],[T]]]],[11,R[76],E,E,17,[[[U]],[R[74]]]],[11,R[77],E,E,17,[[],[R[74]]]],[11,R[84],E,E,17,[[["self"]],[T]]],[11,R[78],E,E,17,[[["self"]],[T]]],[11,R[81],E,E,17,[[["self"]],[R[85]]]],[11,"vzip",E,E,17,[[],["v"]]],[11,"into",E,E,16,[[],[U]]],[11,"from",E,E,16,[[[T]],[T]]],[11,R[79],E,E,16,[[["self"]],[T]]],[11,R[80],E,E,16,[[["self"],[T]]]],[11,R[76],E,E,16,[[[U]],[R[74]]]],[11,R[77],E,E,16,[[],[R[74]]]],[11,R[84],E,E,16,[[["self"]],[T]]],[11,R[78],E,E,16,[[["self"]],[T]]],[11,R[81],E,E,16,[[["self"]],[R[85]]]],[11,"vzip",E,E,16,[[],["v"]]],[11,"into",R[94],E,20,[[],[U]]],[11,"from",E,E,20,[[[T]],[T]]],[11,R[79],E,E,20,[[["self"]],[T]]],[11,R[80],E,E,20,[[["self"],[T]]]],[11,R[76],E,E,20,[[[U]],[R[74]]]],[11,R[77],E,E,20,[[],[R[74]]]],[11,R[84],E,E,20,[[["self"]],[T]]],[11,R[78],E,E,20,[[["self"]],[T]]],[11,R[81],E,E,20,[[["self"]],[R[85]]]],[11,"vzip",E,E,20,[[],["v"]]],[11,"into",E,E,19,[[],[U]]],[11,"from",E,E,19,[[[T]],[T]]],[11,R[79],E,E,19,[[["self"]],[T]]],[11,R[80],E,E,19,[[["self"],[T]]]],[11,R[76],E,E,19,[[[U]],[R[74]]]],[11,R[77],E,E,19,[[],[R[74]]]],[11,R[84],E,E,19,[[["self"]],[T]]],[11,R[78],E,E,19,[[["self"]],[T]]],[11,R[81],E,E,19,[[["self"]],[R[85]]]],[11,"vzip",E,E,19,[[],["v"]]],[11,"into",R[95],E,46,[[],[U]]],[11,"from",E,E,46,[[[T]],[T]]],[11,R[79],E,E,46,[[["self"]],[T]]],[11,R[80],E,E,46,[[["self"],[T]]]],[11,R[76],E,E,46,[[[U]],[R[74]]]],[11,R[77],E,E,46,[[],[R[74]]]],[11,R[84],E,E,46,[[["self"]],[T]]],[11,R[78],E,E,46,[[["self"]],[T]]],[11,R[81],E,E,46,[[["self"]],[R[85]]]],[11,"vzip",E,E,46,[[],["v"]]],[11,"into",R[96],E,47,[[],[U]]],[11,"from",E,E,47,[[[T]],[T]]],[11,R[79],E,E,47,[[["self"]],[T]]],[11,R[80],E,E,47,[[["self"],[T]]]],[11,R[76],E,E,47,[[[U]],[R[74]]]],[11,R[77],E,E,47,[[],[R[74]]]],[11,R[84],E,E,47,[[["self"]],[T]]],[11,R[78],E,E,47,[[["self"]],[T]]],[11,R[81],E,E,47,[[["self"]],[R[85]]]],[11,"vzip",E,E,47,[[],["v"]]],[11,"into",R[97],E,22,[[],[U]]],[11,"from",E,E,22,[[[T]],[T]]],[11,R[79],E,E,22,[[["self"]],[T]]],[11,R[80],E,E,22,[[["self"],[T]]]],[11,R[76],E,E,22,[[[U]],[R[74]]]],[11,R[77],E,E,22,[[],[R[74]]]],[11,R[84],E,E,22,[[["self"]],[T]]],[11,R[78],E,E,22,[[["self"]],[T]]],[11,R[81],E,E,22,[[["self"]],[R[85]]]],[11,"vzip",E,E,22,[[],["v"]]],[11,"into",E,E,21,[[],[U]]],[11,"from",E,E,21,[[[T]],[T]]],[11,R[79],E,E,21,[[["self"]],[T]]],[11,R[80],E,E,21,[[["self"],[T]]]],[11,R[76],E,E,21,[[[U]],[R[74]]]],[11,R[77],E,E,21,[[],[R[74]]]],[11,R[84],E,E,21,[[["self"]],[T]]],[11,R[78],E,E,21,[[["self"]],[T]]],[11,R[81],E,E,21,[[["self"]],[R[85]]]],[11,"vzip",E,E,21,[[],["v"]]],[11,"into",R[98],E,24,[[],[U]]],[11,"from",E,E,24,[[[T]],[T]]],[11,R[76],E,E,24,[[[U]],[R[74]]]],[11,R[77],E,E,24,[[],[R[74]]]],[11,R[84],E,E,24,[[["self"]],[T]]],[11,R[78],E,E,24,[[["self"]],[T]]],[11,R[81],E,E,24,[[["self"]],[R[85]]]],[11,"vzip",E,E,24,[[],["v"]]],[11,"into",E,E,23,[[],[U]]],[11,"from",E,E,23,[[[T]],[T]]],[11,R[79],E,E,23,[[["self"]],[T]]],[11,R[80],E,E,23,[[["self"],[T]]]],[11,R[76],E,E,23,[[[U]],[R[74]]]],[11,R[77],E,E,23,[[],[R[74]]]],[11,R[84],E,E,23,[[["self"]],[T]]],[11,R[78],E,E,23,[[["self"]],[T]]],[11,R[81],E,E,23,[[["self"]],[R[85]]]],[11,"vzip",E,E,23,[[],["v"]]],[11,"into",R[52],E,25,[[],[U]]],[11,"from",E,E,25,[[[T]],[T]]],[11,R[76],E,E,25,[[[U]],[R[74]]]],[11,R[77],E,E,25,[[],[R[74]]]],[11,R[84],E,E,25,[[["self"]],[T]]],[11,R[78],E,E,25,[[["self"]],[T]]],[11,R[81],E,E,25,[[["self"]],[R[85]]]],[11,"vzip",E,E,25,[[],["v"]]],[11,"into",E,E,26,[[],[U]]],[11,"from",E,E,26,[[[T]],[T]]],[11,R[79],E,E,26,[[["self"]],[T]]],[11,R[80],E,E,26,[[["self"],[T]]]],[11,R[76],E,E,26,[[[U]],[R[74]]]],[11,R[77],E,E,26,[[],[R[74]]]],[11,R[84],E,E,26,[[["self"]],[T]]],[11,R[78],E,E,26,[[["self"]],[T]]],[11,R[81],E,E,26,[[["self"]],[R[85]]]],[11,"vzip",E,E,26,[[],["v"]]],[11,"into",E,E,27,[[],[U]]],[11,"from",E,E,27,[[[T]],[T]]],[11,R[79],E,E,27,[[["self"]],[T]]],[11,R[80],E,E,27,[[["self"],[T]]]],[11,R[76],E,E,27,[[[U]],[R[74]]]],[11,R[77],E,E,27,[[],[R[74]]]],[11,R[84],E,E,27,[[["self"]],[T]]],[11,R[78],E,E,27,[[["self"]],[T]]],[11,R[81],E,E,27,[[["self"]],[R[85]]]],[11,"vzip",E,E,27,[[],["v"]]],[11,"into",E,E,28,[[],[U]]],[11,"from",E,E,28,[[[T]],[T]]],[11,R[79],E,E,28,[[["self"]],[T]]],[11,R[80],E,E,28,[[["self"],[T]]]],[11,R[76],E,E,28,[[[U]],[R[74]]]],[11,R[77],E,E,28,[[],[R[74]]]],[11,R[84],E,E,28,[[["self"]],[T]]],[11,R[78],E,E,28,[[["self"]],[T]]],[11,R[81],E,E,28,[[["self"]],[R[85]]]],[11,"vzip",E,E,28,[[],["v"]]],[11,"into",E,E,29,[[],[U]]],[11,"from",E,E,29,[[[T]],[T]]],[11,R[79],E,E,29,[[["self"]],[T]]],[11,R[80],E,E,29,[[["self"],[T]]]],[11,R[76],E,E,29,[[[U]],[R[74]]]],[11,R[77],E,E,29,[[],[R[74]]]],[11,R[84],E,E,29,[[["self"]],[T]]],[11,R[78],E,E,29,[[["self"]],[T]]],[11,R[81],E,E,29,[[["self"]],[R[85]]]],[11,"vzip",E,E,29,[[],["v"]]],[11,"into",E,E,30,[[],[U]]],[11,"from",E,E,30,[[[T]],[T]]],[11,R[79],E,E,30,[[["self"]],[T]]],[11,R[80],E,E,30,[[["self"],[T]]]],[11,R[76],E,E,30,[[[U]],[R[74]]]],[11,R[77],E,E,30,[[],[R[74]]]],[11,R[84],E,E,30,[[["self"]],[T]]],[11,R[78],E,E,30,[[["self"]],[T]]],[11,R[81],E,E,30,[[["self"]],[R[85]]]],[11,"vzip",E,E,30,[[],["v"]]],[11,"into",R[99],E,31,[[],[U]]],[11,"from",E,E,31,[[[T]],[T]]],[11,R[76],E,E,31,[[[U]],[R[74]]]],[11,R[77],E,E,31,[[],[R[74]]]],[11,R[84],E,E,31,[[["self"]],[T]]],[11,R[78],E,E,31,[[["self"]],[T]]],[11,R[81],E,E,31,[[["self"]],[R[85]]]],[11,"vzip",E,E,31,[[],["v"]]],[11,"into",E,E,32,[[],[U]]],[11,"from",E,E,32,[[[T]],[T]]],[11,R[79],E,E,32,[[["self"]],[T]]],[11,R[80],E,E,32,[[["self"],[T]]]],[11,R[100],E,E,32,[[["self"]],[R[19]]]],[11,R[76],E,E,32,[[[U]],[R[74]]]],[11,R[77],E,E,32,[[],[R[74]]]],[11,R[84],E,E,32,[[["self"]],[T]]],[11,R[78],E,E,32,[[["self"]],[T]]],[11,R[81],E,E,32,[[["self"]],[R[85]]]],[11,"vzip",E,E,32,[[],["v"]]],[11,"into",E,E,48,[[],[U]]],[11,"from",E,E,48,[[[T]],[T]]],[11,R[79],E,E,48,[[["self"]],[T]]],[11,R[80],E,E,48,[[["self"],[T]]]],[11,R[100],E,E,48,[[["self"]],[R[19]]]],[11,R[76],E,E,48,[[[U]],[R[74]]]],[11,R[77],E,E,48,[[],[R[74]]]],[11,R[84],E,E,48,[[["self"]],[T]]],[11,R[78],E,E,48,[[["self"]],[T]]],[11,R[81],E,E,48,[[["self"]],[R[85]]]],[11,"vzip",E,E,48,[[],["v"]]],[11,"into",R[101],E,34,[[],[U]]],[11,"from",E,E,34,[[[T]],[T]]],[11,R[76],E,E,34,[[[U]],[R[74]]]],[11,R[77],E,E,34,[[],[R[74]]]],[11,R[84],E,E,34,[[["self"]],[T]]],[11,R[78],E,E,34,[[["self"]],[T]]],[11,R[81],E,E,34,[[["self"]],[R[85]]]],[11,"vzip",E,E,34,[[],["v"]]],[11,"into",E,E,49,[[],[U]]],[11,"from",E,E,49,[[[T]],[T]]],[11,R[79],E,E,49,[[["self"]],[T]]],[11,R[80],E,E,49,[[["self"],[T]]]],[11,R[100],E,E,49,[[["self"]],[R[19]]]],[11,R[76],E,E,49,[[[U]],[R[74]]]],[11,R[77],E,E,49,[[],[R[74]]]],[11,R[84],E,E,49,[[["self"]],[T]]],[11,R[78],E,E,49,[[["self"]],[T]]],[11,R[81],E,E,49,[[["self"]],[R[85]]]],[11,"vzip",E,E,49,[[],["v"]]],[11,"into",E,E,50,[[],[U]]],[11,"from",E,E,50,[[[T]],[T]]],[11,R[79],E,E,50,[[["self"]],[T]]],[11,R[80],E,E,50,[[["self"],[T]]]],[11,R[76],E,E,50,[[[U]],[R[74]]]],[11,R[77],E,E,50,[[],[R[74]]]],[11,R[84],E,E,50,[[["self"]],[T]]],[11,R[78],E,E,50,[[["self"]],[T]]],[11,R[81],E,E,50,[[["self"]],[R[85]]]],[11,"vzip",E,E,50,[[],["v"]]],[11,"into",R[102],E,36,[[],[U]]],[11,"from",E,E,36,[[[T]],[T]]],[11,R[76],E,E,36,[[[U]],[R[74]]]],[11,R[77],E,E,36,[[],[R[74]]]],[11,R[84],E,E,36,[[["self"]],[T]]],[11,R[78],E,E,36,[[["self"]],[T]]],[11,R[81],E,E,36,[[["self"]],[R[85]]]],[11,"vzip",E,E,36,[[],["v"]]],[11,"into",R[70],E,37,[[],[U]]],[11,"from",E,E,37,[[[T]],[T]]],[11,R[79],E,E,37,[[["self"]],[T]]],[11,R[80],E,E,37,[[["self"],[T]]]],[11,R[76],E,E,37,[[[U]],[R[74]]]],[11,R[77],E,E,37,[[],[R[74]]]],[11,R[84],E,E,37,[[["self"]],[T]]],[11,R[78],E,E,37,[[["self"]],[T]]],[11,R[81],E,E,37,[[["self"]],[R[85]]]],[11,"vzip",E,E,37,[[],["v"]]],[11,"into",E,E,38,[[],[U]]],[11,"from",E,E,38,[[[T]],[T]]],[11,R[79],E,E,38,[[["self"]],[T]]],[11,R[80],E,E,38,[[["self"],[T]]]],[11,R[76],E,E,38,[[[U]],[R[74]]]],[11,R[77],E,E,38,[[],[R[74]]]],[11,R[84],E,E,38,[[["self"]],[T]]],[11,R[78],E,E,38,[[["self"]],[T]]],[11,R[81],E,E,38,[[["self"]],[R[85]]]],[11,"vzip",E,E,38,[[],["v"]]],[11,"into",E,E,39,[[],[U]]],[11,"from",E,E,39,[[[T]],[T]]],[11,R[79],E,E,39,[[["self"]],[T]]],[11,R[80],E,E,39,[[["self"],[T]]]],[11,R[76],E,E,39,[[[U]],[R[74]]]],[11,R[77],E,E,39,[[],[R[74]]]],[11,R[84],E,E,39,[[["self"]],[T]]],[11,R[78],E,E,39,[[["self"]],[T]]],[11,R[81],E,E,39,[[["self"]],[R[85]]]],[11,"vzip",E,E,39,[[],["v"]]],[11,R[103],R[82],E,41,[[["self"]],[[R[6],[R[7]]],[R[7]]]]],[11,R[104],E,E,41,[[["self"]],[[R[6],[R[7]]],[R[7]]]]],[11,R[105],E,E,41,[[["self"]],["bool"]]],[11,R[41],E,E,41,[[["vec"],["self"],["rc"]]]],[11,R[103],R[83],E,42,[[["self"]],[[R[6],[R[7]]],[R[7]]]]],[11,R[104],E,E,42,[[["self"]],[[R[6],[R[7]]],[R[7]]]]],[11,R[105],E,E,42,[[["self"]],["bool"]]],[11,R[41],E,E,42,[[["vec"],["self"],["rc"]]]],[11,R[103],R[86],E,43,[[["self"]],[[R[6],[R[7]]],[R[7]]]]],[11,R[104],E,E,43,[[["self"]],[[R[6],[R[7]]],[R[7]]]]],[11,R[105],E,E,43,[[["self"]],["bool"]]],[11,R[41],E,E,43,[[["vec"],["self"],["rc"]]]],[11,R[103],R[87],E,8,[[["self"]],[[R[6],[R[7]]],[R[7]]]]],[11,R[104],E,E,8,[[["self"]],[[R[6],[R[7]]],[R[7]]]]],[11,R[106],E,E,8,[[["self"]],["bool"]]],[11,R[41],E,E,8,[[["rc"],["vec"],["self"]]]],[11,R[107],E,E,8,[[["rc"],["self"],[R[4],[R[5]]],[R[6],[R[4]]]],[[R[4],[R[5]]],[R[6],[R[4]]]]]],[11,R[103],R[88],E,10,[[["self"]],[[R[6],[R[7]]],[R[7]]]]],[11,R[104],E,E,10,[[["self"]],[[R[6],[R[7]]],[R[7]]]]],[11,R[106],E,E,10,[[["self"]],["bool"]]],[11,R[41],E,E,10,[[["rc"],["vec"],["self"]]]],[11,R[107],E,E,10,[[["rc"],["self"],[R[4],[R[5]]],[R[6],[R[4]]]],[[R[4],[R[5]]],[R[6],[R[4]]]]]],[11,R[106],R[89],E,12,[[["self"]],["bool"]]],[11,R[41],E,E,12,[[["vec"],["self"],["rc"]]]],[11,R[103],E,E,12,[[["self"]],[[R[6],[R[7]]],[R[7]]]]],[11,R[41],R[90],E,44,[[["vec"],["self"],["rc"]]]],[11,R[103],R[91],E,15,[[["self"]],[[R[6],[R[7]]],[R[7]]]]],[11,R[104],E,E,15,[[["self"]],[[R[6],[R[7]]],[R[7]]]]],[11,R[41],E,E,15,[[["vec"],["self"],["rc"]]]],[11,R[41],R[92],E,45,[[["vec"],["self"],["rc"]]]],[11,R[103],R[93],E,17,[[["self"]],[[R[6],[R[7]]],[R[7]]]]],[11,R[104],E,E,17,[[["self"]],[[R[6],[R[7]]],[R[7]]]]],[11,R[41],E,E,17,[[["vec"],["self"],["rc"]]]],[11,R[103],R[94],E,20,[[["self"]],[[R[6],[R[7]]],[R[7]]]]],[11,R[104],E,E,20,[[["self"]],[[R[6],[R[7]]],[R[7]]]]],[11,R[108],E,E,20,[[["self"]],["bool"]]],[11,R[109],E,E,20,[[["self"],[R[7]]],[["f32"],[R[6],["f32"]]]]],[11,R[110],E,E,20,[[["self"]],["bool"]]],[11,R[41],E,E,20,[[["vec"],["self"],["rc"]]]],[11,R[41],R[95],E,46,[[["vec"],["self"],["rc"]]]],[11,R[105],R[97],E,22,[[["self"]],["bool"]]],[11,R[108],E,E,22,[[["self"]],["bool"]]],[11,R[41],E,E,22,[[["vec"],["self"],["rc"]]]],[11,R[111],R[98],E,24,[[["self"]],["bool"]]],[11,R[112],E,E,24,[[["self"]],[[R[6],["vec"]],["vec",[R[4]]]]]],[11,R[113],E,E,24,[[["self"]],[[R[6],["vec"]],["vec",[R[4]]]]]],[11,R[114],E,E,24,[[["self"]],[[R[6],["vec"]],["vec",[R[4]]]]]],[11,R[115],E,E,24,[[["self"]],[[R[6],["vec"]],["vec",[R[4]]]]]],[11,R[116],E,E,24,[[["self"]],[[R[6],["vec"]],["vec",[R[4]]]]]],[11,R[14],E,E,24,[[["self"]],[[R[6],["vec"]],["vec",[R[4]]]]]],[11,R[15],E,E,24,[[["self"]],[[R[6],["vec"]],["vec",[R[19]]]]]],[11,R[107],E,E,24,[[["rc"],["self"],[R[4],[R[5]]],[R[6],[R[4]]]],[[R[4],[R[5]]],[R[6],[R[4]]]]]],[11,"forward",E,E,24,[[["b"],["self"]]]],[11,R[11],E,E,24,[[["b"],["self"]]]],[11,R[12],E,E,24,[[["b"],["self"]]]],[11,R[117],R[82],E,41,[[["b"],["self"]]]],[11,R[117],R[83],E,42,[[["b"],["self"]]]],[11,R[117],R[86],E,43,[[["b"],["self"]]]],[11,R[117],R[87],E,8,[[["b"],["self"]]]],[11,R[117],R[88],E,10,[[["b"],["self"]]]],[11,R[117],R[89],"Basically, x has the shape (k, n) where k is the batch…",12,[[["b"],["self"]]]],[11,R[117],R[90],E,44,[[["b"],["self"]]]],[11,R[117],R[91],E,15,[[["b"],["self"]]]],[11,R[117],R[92],E,45,[[["b"],["self"]]]],[11,R[117],R[93],E,17,[[["b"],["self"]]]],[11,R[117],R[94],E,20,[[["b"],["self"]]]],[11,R[117],R[95],E,46,[[["b"],["self"]]]],[11,R[117],R[97],E,22,[[["b"],["self"]]]],[11,R[117],R[98],E,24,[[["b"],["self"]]]],[11,R[118],R[82],E,41,[[["b"],["self"]]]],[11,R[118],R[83],E,42,[[["b"],["self"]]]],[11,R[118],R[86],E,43,[[["b"],["self"]]]],[11,R[118],R[87],E,8,[[["b"],["self"]]]],[11,R[118],R[88],E,10,[[["b"],["self"]]]],[11,R[118],R[89],"Since we have row vectors instead of columns, xW^T =…",12,[[["b"],["self"]]]],[11,R[118],R[90],E,44,[[["b"],["self"]]]],[11,R[118],R[91],E,15,[[["b"],["self"]]]],[11,R[118],R[92],E,45,[[["b"],["self"]]]],[11,R[118],R[93],E,17,[[["b"],["self"]]]],[11,R[118],R[94],E,20,[[["b"],["self"]]]],[11,R[118],R[95],E,46,[[["b"],["self"]]]],[11,R[118],R[97],E,22,[[["b"],["self"]]]],[11,R[118],R[98],E,24,[[["b"],["self"]]]],[11,R[119],R[87],E,8,[[["b"],["self"]]]],[11,R[119],R[88],E,10,[[["b"],["self"]]]],[11,R[119],R[89],E,12,[[["b"],["self"]]]],[11,R[119],R[98],E,24,[[["b"],["self"]]]],[11,R[120],R[87],R[121],8,[[["self"]],[R[7]]]],[11,R[122],E,E,8,[[["self"]],[[R[7]],["vec",[R[7]]]]]],[11,R[32],E,E,8,[[["self"]]]],[11,"stride",E,E,8,[[["self"]]]],[11,R[36],E,E,8,[[["self"]]]],[11,R[120],R[91],R[121],15,[[["self"]],[R[7]]]],[11,R[122],E,E,15,[[["self"]],[[R[7]],["vec",[R[7]]]]]],[11,R[32],E,E,15,[[["self"]]]],[11,"stride",E,E,15,[[["self"]]]],[11,R[36],E,E,15,[[["self"]]]],[11,"loss",R[101],E,50,[[["self"]],["f32"]]],[11,"init",R[102],"Initialize the SGD Momentum solver, allocating memory for…",36,[[["self"],["layer"]]]],[11,R[123],E,E,36,[[["layer"],[R[7]],["self"],[R[61]]]]],[11,"backend",E,E,36,[[["self"]],["solverb"]]],[11,"into",R[87],E,7,[[],[R[17]]]],[11,"into",R[88],E,9,[[],[R[17]]]],[11,"into",R[89],E,11,[[],[R[17]]]],[11,"into",R[91],E,13,[[],[R[17]]]],[11,"into",R[93],E,16,[[],[R[17]]]],[11,"into",R[94],E,19,[[],[R[17]]]],[11,"into",R[97],E,21,[[],[R[17]]]],[11,"into",R[98],E,23,[[],[R[17]]]],[11,"clone",R[75],E,1,[[["self"]],[R[18]]]],[11,"clone",E,E,2,[[["self"]],[R[17]]]],[11,"clone",R[82],E,41,[[["self"]],["relu"]]],[11,"clone",R[83],E,42,[[["self"]],["sigmoid"]]],[11,"clone",R[86],E,43,[[["self"]],["tanh"]]],[11,"clone",R[87],E,8,[[["self"]],[R[26]]]],[11,"clone",E,E,7,[[["self"]],[R[124]]]],[11,"clone",R[88],E,10,[[["self"]],["rnn"]]],[11,"clone",E,E,9,[[["self"]],[R[125]]]],[11,"clone",R[89],E,11,[[["self"]],[R[126]]]],[11,"clone",R[90],E,44,[[["self"]],[R[131]]]],[11,"clone",R[91],E,15,[[["self"]],["pooling"]]],[11,"clone",E,E,13,[[["self"]],[R[127]]]],[11,"clone",E,E,14,[[["self"]],["poolingmode"]]],[11,"clone",R[92],E,45,[[["self"]],["softmax"]]],[11,"clone",R[93],E,17,[[["self"]],["dropout"]]],[11,"clone",E,E,16,[[["self"]],[R[128]]]],[11,"clone",R[94],E,20,[[["self"]],[R[129]]]],[11,"clone",E,E,19,[[["self"]],[R[130]]]],[11,"clone",R[95],E,46,[[["self"]],[R[132]]]],[11,"clone",R[96],E,47,[[["self"]],["flatten"]]],[11,"clone",R[97],E,22,[[["self"]],[R[41]]]],[11,"clone",E,E,21,[[["self"]],[R[42]]]],[11,"clone",R[98],E,23,[[["self"]],[R[46]]]],[11,"clone",R[99],E,32,[[["self"]],["sample"]]],[11,"clone",E,E,48,[[["self"]],[R[51]]]],[11,"clone",R[101],E,49,[[["self"]],["sample"]]],[11,"clone",E,E,50,[[["self"]],["meansquarederroraccuracy"]]],[11,"clone",R[52],E,26,[[["self"]],[R[61]]]],[11,"clone",E,E,27,[[["self"]],["solverkind"]]],[11,"clone",E,E,28,[[["self"]],["sgdkind"]]],[11,"clone",E,E,29,[[["self"]],["lrpolicy"]]],[11,"clone",E,E,30,[[["self"]],["regularizationmethod"]]],[11,"clone",R[70],E,37,[[["self"]],[R[20]]]],[11,"clone",E,E,38,[[["self"]],["dimcheckmode"]]],[11,"clone",E,E,39,[[["self"]],["fillertype"]]],[11,R[133],R[89],E,12,[[],["linear"]]],[11,R[133],R[90],E,44,[[],[R[131]]]],[11,R[133],R[92],E,45,[[],["softmax"]]],[11,R[133],R[93],E,16,[[],[R[128]]]],[11,R[133],R[95],E,46,[[],[R[132]]]],[11,R[133],R[98],E,23,[[],[R[46]]]],[11,R[133],R[52],E,26,[[],[R[61]]]],[11,R[133],R[70],E,37,[[],[R[20]]]],[11,"fmt",R[99],E,32,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,48,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[101],E,49,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,33,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[75],E,0,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,3,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,1,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,2,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[82],E,41,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[83],E,42,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[86],E,43,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[87],E,8,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,7,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[88],E,10,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,9,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[89],E,12,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,11,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[90],E,44,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[91],E,15,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,13,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,14,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[92],E,45,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[93],E,17,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,16,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[94],E,20,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,19,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[95],E,46,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[96],E,47,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[97],E,22,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,21,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[98],E,24,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,23,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[99],E,31,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,32,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,48,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[101],E,34,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,49,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,50,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[52],E,25,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,35,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,26,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,27,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,28,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,29,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,30,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[102],E,36,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",R[70],E,37,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,38,[[["self"],[R[134]]],[R[74]]]],[11,"fmt",E,E,39,[[["self"],[R[134]]],[R[74]]]]],"p":[[3,"Layer"],[3,R[135]],[4,R[136]],[8,"ILayer"],[8,R[137]],[8,R[138]],[8,R[139]],[3,R[140]],[3,R[23]],[3,R[141]],[3,"Rnn"],[3,R[142]],[3,"Linear"],[3,R[143]],[4,R[144]],[3,"Pooling"],[3,R[145]],[3,R[3]],[8,R[146]],[3,R[147]],[3,R[37]],[3,R[148]],[3,"Reshape"],[3,R[149]],[3,R[43]],[3,"Solver"],[3,R[150]],[4,R[151]],[4,"SGDKind"],[4,"LRPolicy"],[4,R[152]],[3,R[153]],[3,"Sample"],[8,R[154]],[3,R[155]],[8,"ISolver"],[3,R[69]],[3,R[156]],[4,R[157]],[4,R[158]],[8,"Axpby"],[3,"ReLU"],[3,"Sigmoid"],[3,"TanH"],[3,R[29]],[3,"Softmax"],[3,R[39]],[3,"Flatten"],[3,"Accuracy"],[3,"Sample"],[3,R[159]]]};
initSearch(searchIndex);addSearchOptions(searchIndex);